# Ranged requests, checksum storing and Redis

The [zip file format](https://en.wikipedia.org/wiki/Zip_(file_format)) requires [CRC32 checksums](https://en.wikipedia.org/wiki/Cyclic_redundancy_check) in several places, to verify file integrity. Not all zip clients actually verify these checksums against the file content but most do. So, to prevent errors and/or warnings when users open zip files generated by the streamer, we need to add the checksums.

### Normal (full-file) streaming

When streaming an entire zip archive, providing the checksums is not a problem. ZipTricks keep track of the checksum as the file gets written and makes sure the final value is inserted in all the appropriate headers. In particular, the checksum for a file is included in the "data descriptor" that gets inserted after the contents of every file. The checksums for each file are also included in the "central directory" containing metadata about all files, which is located.at the end of the zip file.

### Ranged requests

When a client makes a ranged HTTP request, things get more tricky. It is for example possible to only request the bytes making up the central directory. However, in that case the request will not have had the opportunity to compute the checksums for each file and so it cannot know which bytes to fill in for the checksums. Somehow it needs to get a hold of the checksums *before* it can begin constructing a ranged request.

## Checksum storing

The servers are all connected to a common Redis instance that stores checksums for URLs. The key used are the URLs themselves and the values are JSON values encoded versions of Ruby hashes. There are three possible values for any url:

- `nil`. If a key is `nil`, no checksum is known for this URL. The server will kick off a separate thread to compute the checksum and store it in Redis using the `fetch_single_checksum` method of `ZipStreamer`.
- `{state: "pending"}`. If a key is present but the state value is `"pending"`, then another request is already working to compute the checksum and has put a placeholder value in Redis to prevent duplicate work. The first thing that `fetch_single_checksum` will do is atomically check if the another thread is already doing its work. If this value is encountered, the `ZipStreamer` won't compute the checksum again but will poll Redis for up to 30 seconds to wait for the results of the other thread. The placeholders are always written with a 30 second expiry, so even if the thread somehow crashes or is interrupted, subsequent requests will not be stuck waiting for a result that never comes. 
- `{state: "done", etag: "some_value", crc32: 12345}`. If a key is present and the state is `"done"`, the checksum is known. We also store the etag originally returned with the contents that the checksum was computed from, for the case that the URL contents have changed since initial checksumming. This value can be written by `fetch_single_checksum`, it will also be written during normal (non-ranged) downloads, after each file. No expiry is set for these values.

The expectation is that requests for the whole file will greatly outnumber ranged requests and so almost every checksum that is needed will already be present in the Redis. It is also expected that the total different number of files will not be "too" great for the foreseeable future and will therefore easily fit into Redis.
